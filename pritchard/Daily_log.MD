# Daily Progress Report
----------------------------------------------
### Week 1: 5/31 to 6/3 ###
#### Tuesday May 31th ####
- [ ] Attended the first introduction session
- [ ] Got workday details in order, including banking

#### Wednesday June 1th ####
- [ ] Attended the second introduction session
- [ ] Obtained Argonne badge
- [ ] Took mandatory TMS courses

#### Thursday June 2th ####
- [ ] Gained access to teams channel
- [ ] Gained access to email/authenticator app
- [ ] Gained access to my.anl.gov
- [ ] Made Github account/practiced making files and editing them
- [ ] Met with Abayomi to learn about Summer2022 slack and the tutorials we are supposed to go through 
- [ ] Went through pywaggle code base, compiled questions on portions I didn't understand

Things to do: 
- [ ] Ask Raj about signing Taylor University supervisor agreement
- [ ] Get github permission to edit Summer2022
- [ ] Figure out how to record daily logs on github
- [ ] Gather all questions together for eventual meeting with Raj
- [ ] Conduct basic research on "LoRaWan"

#### Friday June 3th ####
- [ ] Looked through Summer 2020 repo
  - [ ] Followed through tutorials 
  - [ ] Setup required accounts
  - [ ] Found bugs in repo links, in tiles and Dialylogs access

Things to do:
- [ ] Talk with Raj about questions, bugs in Summer2022 repo and supervisor agreement

### Week 2: 6/6 to 6/10 ###
#### Monday June 6th ####
- [ ] Made a word doc containing previous python issues and repo bugs
- [ ] Messaged Raj about bugs in repo 
- [ ] Organized list of questions
- [ ] Worked out much of prevoius pywaggle related questions for Raj

Things to do:
- [ ] Talk with Raj about pywaggle and basic project questions, bugs in Summer2022 repo and supervisor agreement

#### Tuesday June 7th ####
- [ ] Met with Raj to talk about what I will be doing in the project, clarified that I can get my pywaggle questions ansewered later n project
- [ ] Received WisGate, Rakpi, Nvidea nano, partialy broken mini router, and ethernet cabels 
- [ ] Began process of getting received devices all connected through ethernet
- [ ] Got firmware images of Nvidea nano and RAKpi updated

Things to do:
- [ ] Re-do supervisor agreement and get signature
- [ ] Finish setting up and connecting to recevied devices

#### Wednesday June 8th ####
- [ ] Attended the required participation wedsday lecture
- [ ] Learned linux commands for accessing devices over ethernet 
- [ ] Finished connecting to and initializing all devices
- [ ] Got Github access aproved

Things to do:  
- [ ] Re-do supervisor agreement and get signature
- [ ] Create virtual daily log
- [ ] Prepare for presentation on friday about WisGate VS RAZPi

#### Thursday June 9th ####
- [ ] Attended AI seminar
- [ ] Attended workplace violence seminar
- [ ] Rewrote supervisor agreement
- [ ] Joined sage slack
- [ ] Finished pre-hire survey
- [ ] Researched for presentation on friday about WisGate VS RAZPi

Things to do: 
- [ ] Re-do supervisor agreement and get signature
- [ ] Create virtual daily log
- [ ] Prepare for presentation on friday about WisGate VS RAZPi

#### Friday June 10th ####
- [ ] Rewrote paper and recived signature
- [ ] Finished updating to current Waggle daily journal
- [ ] Researched for presentation
- [ ] Gave presentation, 

Things to do:
- [ ] Fix broken WisGateway

### Week 3: 6/13 to 6/17 ###
#### Monday June 13th ####
- [ ] Fixed broken WisGateway by using recovery software and redownloading firmware
- [ ] Attended writing workshop introduction
- [ ] Talked to Raj about buying senors to act as end nodes: he agreed
- [ ] Reiceved instruction: Raj wants me and other interns to set up bike racks for sensor testing, some week not 100F

Things to do:
- [ ] Update daily journal
- [ ] Talk to Raj about setting up Creat robot
- [ ] Make shopping list of sensors and needed parts

#### Tuesday June 14th ####
- [ ] Make shopping list of sensors and needed parts
```
Sensor types
Arduino:
MKRWAN1310 https://docs.arduino.cc/hardware/mkr-wan-1310
Sold out so earlier version :
https://store-usa.arduino.cc/products/arduino-mkr-wan-1300-lora-connectivity?selectedStore=us
somehow version still visible on amazon:
https://www.amazon.com/Arduino-MKR-1310-Antenna-Included/dp/B07XVJYTJG/ref=sr_1_1?crid=34B9JI6FJLYU1&keywords=MKR%2BWAN%2B1310&qid=1655231621&sprefix=mkr%2Bwan%2B1310%2Caps%2C136&sr=8-1&th=1
Arduino sensors (Light, temp ext.) Breadboard and wires (assuming we have those)
WisBlock
Base:
https://docs.rakwireless.com/Product-Categories/WisBlock/RAK19007/Overview/
requires type c- cable to begin development, and additional cables to use remotely
https://store.rakwireless.com/products/rak19007-wisblock-base-board-2nd-gen
Core:
https://docs.rakwireless.com/Product-Categories/WisBlock/RAK4631/Overview/
https://store.rakwireless.com/products/rak4631-lpwan-node?variant=37505443987654
if Bluetooth not helpful:
https://store.rakwireless.com/products/rak11310-wisblock-lpwan-module
Sensor:
https://docs.rakwireless.com/Product-Categories/WisBlock/RAK12003/Overview/ temperature
https://store.rakwireless.com/products/infrared-temperature-sensor-rak12003
https://docs.rakwireless.com/Product-Categories/WisBlock/RAK12005/Overview/ Rain
https://store.rakwireless.com/products/rain-sensor-rak12005-module-and-rak12030-sensor
https://docs.rakwireless.com/Product-Categories/WisBlock/RAK12015/Overview/ vibration detection
https://store.rakwireless.com/products/wisblock-vibration-sensor-rak12015
https://docs.rakwireless.com/Product-Categories/WisBlock/RAK1903/Overview/ light sensor
https://store.rakwireless.com/products/rak1903-opt3001dnpr-ambient-light-sensor

```
- [ ] Updated daily journal
- [ ] Attended student connection group session
- [ ] Presented shopping list to Raj-> Decided we would use arduinos instead of RAK based WisBlock

Things to do:
- [ ] Find antenna for MKR WAN 1300 Arduino

#### Wednesday June 15th ####
- [ ] Found antenna for MKR WAN 1300 Arduino
- [ ] Updated daily log
- [ ] Attended seminar on graduate studies options
- [ ] Met with Andre (over slack) to bring him up to speed
- [ ] Applied for Waggle summer get together
- [ ] Met with Raj about purchasing anntena
- [ ] Found some related tutorials and information on using MKR Wan 1310 chips
- [ ] Completed Student Pulse survey
- [ ] Did some more Lora vs Lora Wan research

Things to do:  
- [ ] Improve Daily Log quality
- [ ] Read and take notes on four acamemic articles relevant to LoRa/LoRaWAN
- [ ] Make slide presentation on project relevant information from articles 
- [ ] Experiment with nano

#### Thursday June 16th ####
- [ ]  Read and took notes on four acamemic articles relevant to LoRa/LoRaWAN
- [ ]  Spoke to Raj about what he cared about for the research presentation
- [ ]  Helped settle Andre into project

Things to do: 
- [ ] Finishing the presentation on LoraWAN research

#### Friday June 17th ####
- [ ] Finished the presentation, [you can find powerpoint here](https://github.com/waggle-sensor/summer2022/blob/main/pritchard/WisgateProgress/LoRaWAN%20Research.pdf)
- [ ] Presented the presentation
- [ ] Found space on 7th floor where I could work

Things to do:
- [ ] Setup linux laptop so I can use it as my main computer at work
- [ ] Talk to Raj about: when arduinos will be in, when I will set up bike racks, how I should go about setting up a network server,

### Week 4: 6/20 to 6/24 ###
#### Monday June 20th ####
- [ ] Got outlook/Github/slack/setup on linux computer
- [ ] Talked with Raj about: arduino arrvial date, when we would be setting up bike racks to act as testing rigs, how I should go a bout testing the nano's interaction with the WisGate
- [ ] setup LoRaWAN server on Nano so as to communicate with WisGate acting as a gateway

Things to do:
- [ ] Talk about future project steps with Raj and Andre

#### Tuesday June 21th ####
- [ ] Met with Raj and Andre, clarified that we want the gateway to also act as a network server, and verified that the next step will be to figure out how to communicate with Nvidia Nano
- [ ] researched how we can get data from the network server on the WisGate to the Nano, two feasable methods were grabbing off the local api or via the built in mqtt broker
- [ ] participated in required weekly student meeting

Things to do:
- [ ] make the Nano talk with the WisGate via the MQTT broker which includes figuring out how to setup a mqtt client on the nano

#### Wednesday June 22th ####
- [ ] setup bike raks outside as testing rigs for nodes
- [ ] helped setup 4th floor lab
- [ ] did research on how to register with and recieve messages from Wisgate MQTT broker

Things to do:  
- [ ] settle the communication path with the broker

#### Thursday June 23th ####
- [ ]  Rediscovered Ip adress of WisGate
- [ ]  reconnected everything to Wireless
- [ ]  decided on using Paho library in Python to make barebones client
- [ ]  successfully sent message to WisGate MQTT broker

![image](https://user-images.githubusercontent.com/106760508/182721700-261c6ff5-670b-417b-a056-a540036d34b0.png)
<br>
Things to do: 
- [ ] get WisGate to send message through MQTT broker from its inputs

#### Friday June 24th/weekend ####
- [ ] unsussessfully tried to connect WisGate to home router for serveral hours
- [ ] discoered that WisGate cannot send broker messages over self generated Wifi network
- [ ] did some research on RAK serial port tool

Things to do:
- [ ] Get WisGate to accept some fake data via RAK serial port tool 

### Week 5: 6/27 to 6/31 ###
#### Monday June 27th ####
- [ ] discovered that RAK serial port tool can only be used on "devices" that are sensors
- [ ] messed up wireless network while trying to implement previous test
- [ ] figured out workaround for notation problem when labling MQTT topics/ topics san be refered to using "wildcards" like "+" in wisGate terminal, but will still update from messages from the Nano client that fall within a smaller domain 
- [ ] Began working on EdgeSwitch project, goal: to monitor specific conditions of particular ports via automated ssh and activly display said data in local system
- [ ] Found related commands to display required data over ssh

Things to do:
- [ ] write python file to monitor specific conditions of particular ports via automated ssh and activly display said data in local system

#### Tuesday June 28th ####
- [ ] made some progress on writing automated ssh code
- [ ] learned of previously made repo that spits out slightly different data from that what I am looking for from same edge switch
- [ ] upon further analysis found that repo used the locally hosted api
- [ ] with Raj's help got a basic main.py to print out large section of port data
- [ ] spent time learing about parsing json
- [ ] made initial testing file that relied upon a .JSON file filled with the contents of what was originally spit out by the main.py to attempt to parse said printed out data for what we want

Things to do:
- [ ] parse data

#### Wednesday June 29th ####
- [ ] went to summer meetup
- [ ] did an hour of research on the error I got the day before

Things to do:  
- [ ] parse .Json data

#### Thursday June 30th ####
- [ ]  discovered that error resulted from the printing of the data which converts the data to something unreadable to parsing methods
- [ ]  began working in original main.py file 
- [ ]  discovered that the file that is imported into main.py is in the form of a list instead of a JSON object and attempts to convert said list to Python dictionary or JSON result in a single member list

Things to do: 
- [ ] figure out how to get an output that can be read as a python dictionary

#### Friday June 31th ####
- [ ] switched laptops after repeated crashing
- [ ] Raj decided we will move forwards with rack pie and leave WisGate behind for now
- [ ] successfully accessed and parsed data from EdgeSwitch 8
- [ ] ![image](https://user-images.githubusercontent.com/106760508/176968684-959c4733-54df-4bb4-a4a6-b44d601e7a6f.png)
- [ ] ![image](https://user-images.githubusercontent.com/106760508/176968819-f7d14522-4b78-4139-b6a8-c742f23132e3.png)
- [ ] my code essentially excepts a passed list, which is obtained from a local api using the given credentials, reformats it, then accesses the first element of it which is actually a python dictionary
- [ ] after that a specific section of that library that conatins details useful to us, (interfaces), is taken and then sliced again to find the specific value we are looking for, in this case the first poe wattage value

### Week 6: 6/27 to 6/31 ###
#### Monday June 27th ####
- [ ] discovered that RAK serial port tool can only be used on "devices" that are sensors
- [ ] messed up wireless network while trying to implement previous test
- [ ] figured out workaround for notation problem when labling MQTT topics/ topics san be refered to using "wildcards" like "+" in wisGate terminal, but will still update from messages from the Nano client that fall within a smaller domain 
- [ ] Began working on EdgeSwitch project, goal: to monitor specific conditions of particular ports via automated ssh and activly display said data in local system
- [ ] Found related commands to display required data over ssh

Things to do:
- [ ] write python file to monitor specific conditions of particular ports via automated ssh and activly display said data in local system

#### Tuesday June 28th ####
- [ ] made some progress on writing automated ssh code
- [ ] learned of previously made repo that spits out slightly different data from that what I am looking for from same edge switch
- [ ] upon further analysis found that repo used the locally hosted api
- [ ] with Raj's help got a basic main.py to print out large section of port data
- [ ] spent time learing about parsing json
- [ ] made initial testing file that relied upon a .JSON file filled with the contents of what was originally spit out by the main.py to attempt to parse said printed out data for what we want

Things to do:
- [ ] parse data

#### Wednesday June 29th ####
- [ ] went to summer meetup
- [ ] did an hour of research on the error I got the day before

Things to do:  
- [ ] parse .Json data

#### Thursday June 30th ####
- [ ]  discovered that error resulted from the printing of the data which converts the data to something unreadable to parsing methods
- [ ]  began working in original main.py file 
- [ ]  discovered that the file that is imported into main.py is in the form of a list instead of a JSON object and attempts to convert said list to Python dictionary or JSON result in a single member list

Things to do: 
- [ ] figure out how to get an output that can be read as a python dictionary

#### Friday June 31th ####
- [ ] switched laptops after repeated crashing
- [ ] Raj decided we will move forwards with rack pie and leave WisGate behind for now
- [ ] successfully accessed and parsed data from EdgeSwitch 8
- [ ] ![image](https://user-images.githubusercontent.com/106760508/176968684-959c4733-54df-4bb4-a4a6-b44d601e7a6f.png)
- [ ] ![image](https://user-images.githubusercontent.com/106760508/176968819-f7d14522-4b78-4139-b6a8-c742f23132e3.png)
- [ ] my code essentially accepts a passed list, which is obtained from a local api using the given credentials, reformats it, then accesses the first element of it which is actually a python dictionary
- [ ] after that a specific section of that library that conatins details useful to us, (interfaces), is taken and then sliced again to find the specific 
 
### Week 7: 7/5 to 6/31 ###
#### Tuesday July 5 ####
- [ ] WFH due to family member catching covid
- [ ] wrote basic code for prcessing POE outputs by minimum maximum and average in file over 5min interval
- [ ] ![image](https://user-images.githubusercontent.com/106760508/177434446-c4205417-51d2-46cf-9c7b-288f0c5cc0fb.png)



Things to do:
- [ ] fix bugs in code
- [ ] create system for reognizing consistent change in POE levels
- [ ] figure out how to write outputs to CSV file


#### Wednesday June 29th ####
- [ ] Attended seminar on how our oral and postor presentations will work
- [ ] Fixed a bug in code that created a delay after each port read rather than after each iteration of reading all the ports
```
          print ("port", x+1)#line of code was here
        print ("iterations=", y+1)
        time.sleep(1) #set to 10 in final project # is now here

```
- [ ] Adjusted code for testing purposes: added testing print outs and decreased the delay, number of iterations and number of ports tested
```
for y in range(5): #iterations set to 30 in fianl project
 for x in range(3): #iterates through each port, 8 in final
 time.sleep(1) #set to 10 in final project
 
 print (Averages[0])
print (Maximums[0])
print (Minimums[0])
print (pluggschanged[0])
```
- [ ] Added code to allow for notation to determine if port had a power consuming device plugged in or unplugged during testing period
```
if pluggschanged[x]==0: #checks to make sure nothing was plugged into or unplugged from this port since beggining of test
                        if poePower!=0:#checks to see if anything currently plugged in
                                isoncurrent[x]= 'True'
                        else:
                                isoncurrent[x]= 'False'
                        if y==0:
                                isonoriginal[x]=isoncurrent[x]
                        elif isonoriginal[x]!=isoncurrent[x]:
                                if isonoriginal[x]== True:
                                        pluggschanged[x]= 2 #something was unplugged at this port
                                else:
                                        pluggschanged[x]= 1 #something was plugged in at this port
```
- [ ] Added code to write results to csv file
```
header = ['minimums', 'maximums', 'averages', 'pluggschanged', 'Started plugged in']
Port1 = [Minimums[0], Maximums[0], Averages[0], pluggschanged[0], isonoriginal[0]]
with open('edgeswitch.csv', 'a', encoding='UTF8') as f:
        writer = csv.writer(f)
        writer.writerow(header)
        writer.writerow(Port1)
```
- [ ] Added code to ignore Insecure request warning
```
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)
```
- [ ] Spoke with Raj about current progress in project, was directed to focus on using a que to record events
- [ ] Created new file caled Plugin-EdgeSwitchMetrics in repo to contain current progress in project, as well as a readme to describe that progress
- [ ] Spoke to Abayomi about how to use the pywaggle system to set up ifrustructure to send data while still being able to see it locally by setting up a local directory and directing pywaggle to send its logs there via command line, plugin-logls is the name of the directory
```
env PYWAGGLE_LOG_DIR=/plugin-logls 
```

Things to do:  
- [ ] Talk with Raj about which additional variables we want take from api
- [ ] Get Docker fully functional on loaned computer 
- [ ] Set up a working heap system for event notifications
- [ ] Ask about whether I need to use docker
- [ ] Set up connection to Github repo from loaned computer for easy commits
- [ ] look into "warning keyring is skipped, failed to download keyring error"

#### Thursday June 30th ####
- [ ] Recorded previous day's journal
- [ ] Added List of queues system to store events
 ```
import queue
wattagerecorders=[queue.Queue() for i in range(8)] #ceates list of 8 ques for different ports
 ```
- [ ] Altered input testing logic to better fit new storing system
 ```
   if poePower!=0:#checks to see if anything currently plugged in
                        isoncurrent[x]= True
                else:
                        isoncurrent[x]= False
                if y==0|isonrecent[x]!=isoncurrent[x]:#checks to make sure that either this is the first iteration or something has been unplugged/pluggedin
                        wattagerecorders[x].put(datetime.datetime.now())#stores the changes with when they occured
                        wattagerecorders[x].put(isoncurrent[x])
                isonrecent[x]=isoncurrent[x]     
 ```
- [ ] Added code to identify and store date and time per event occurance
 ```
 wattagerecorders[x].put(datetime.datetime.now())#stores the changes with when they occured
 ```
- [ ] Added code to print individual que to csv file by first converting it to a list
 ```
 header2 = ['started on', 'every time it changed', 'what it changed to each time']
que = list(wattagerecorders[0].queue)
with open('edgeswitch.csv', 'A', encoding='UTF8') as f:
        writer = csv.writer(f)
        writer.writerow(header)
        writer.writerow(Port1)
        writer.writerow(header2)
        writer.writerow(que)
 ```
- [ ] Displayed demo of progress to Raj
- [ ] Talked to Raj about what he wants in project: whole json objects stored in que and then parsed as we need from buffer


Things to do: 
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits
- [ ] figure out full system of storing json objects, then recalling and analizing them

#### Friday June 31th ####
- [ ] Made list of all availible values accessible on api page 
```
0.timestamp
0.device.0.identifier
0.device.0.usage
0.device.ram.usage
0.device.ram.free
0.device.ram.total

x is between 0 and 3
0.device.temperatures.x.name
0.device.temperatures.x.type 
0.device.temperatures.x.value
  #two lower ports are poe ports, all types are other
0.device.uptime

x is between 0 and 15
0.interfaces.x.statistics.dropped
0.interfaces.x.statistics.errors
0.interfaces.x.statistics.txErrors
0.interfaces.x.statistics.rxErrors
0.interfaces.x.statistics.rate
0.interfaces.x.statistics.txRate
0.interfaces.x.statistics.rxRate
0.interfaces.x.statistics.bytes
0.interfaces.x.statistics.txBytes
0.interfaces.x.statistics.rxBytes
0.interfaces.x.statistics.packets
0.interfaces.x.statistics.txPackets
0.interfaces.x.statistics.rxPackets
0.interfaces.x.statistics.pps
0.interfaces.x.statistics.txPPS
0.interfaces.x.statistics.rxPPS
0.interfaces.x.statistics.poePower
```
- [ ] Made functions to return particular specified values after receiving the json of a particular iteration
```
def getStatistics(jsonObject,portnumber,variable):# ex: 3 'poePower'
        data=json.loads(jsonObject)
        Statistic=data[0]['interfaces'][portnumber]['statistics'][variable]#port= 0-15, 
        #variable= dropped errors txErrors rxErrors rate txRate rxRate bytes txBytes rxBytes packets txPackets rxPackets pps txPPS rxPPS poePower
        #print('from statistic')
        #print(Statistic, data[0]['timestamp'])
        return(Statistic,data[0]['timestamp'])#return as tuple with timestamp
def getRaminfo(jsonObject,variable):
        data=json.loads(jsonObject)
        RamInfo=data[0]['device']['ram'][variable]#variable = usage, free, total
        return(RamInfo,data[0]['timestamp'])
def getTempinfo(jsonObject,area,variable):#area= 0-3, 
        #variable= name, value, as well as type which is always other
        data=json.loads(jsonObject)
        TempInfo=data[0]['device']['temperatures'][area][variable]
        return(TempInfo,data[0]['timestamp'])
def getTimestamp(jsonObject):
        data=json.loads(jsonObject)
        Timestamp=data[0]['timestamp']
        return(Timestamp) 
def getProcessorUsage(jsonObject):
        data=json.loads(jsonObject)
        ProcessorUsage=data[0]['device']['cpu'][0]['usage'] #second zero might be cpu
        return(ProcessorUsage,data[0]['timestamp'])
def getUptime(jsonObject):
        data=json.loads(jsonObject)
        Uptime=data[0]['device']['uptime']
        return(Uptime,data[0]['timestamp'])
```
- [ ] Figured out how make que of json objects as well as how to run through that que when doing processing for a particular value
```
Queofjson.put(json.dumps(info))
jsonObject=Queofjson.get()
```
- [ ] Figured out how to send out and receive all values in the form of tuples which contain the wanted value as well as the timestamp of when that value occured
```
 Averages =[(0,0)*numberofports]# error creates (0, 0, 0, 0, 0, 0)
temp =Averages[x][0]+(poePower-Averages[x][0])/(y+1) #rolling average calculation
                        Averages[x]=(temp, time)
```
- [ ] Made new versions of previous average, minimum and maximum value finders, sussessfully got average function fully operational
```
def getPOEAverages(jsonqueue):
        #Averages = [0] * numberofports
        #Averages= [0.0 for i in range(numberofports)]
        Averages =[(0,0)*numberofports]# error creates (0, 0, 0, 0, 0, 0)
        #print (type(Averages[0]))
        for y in range(numberiterations):
                jsonObject=jsonqueue.get()
              
                for x in range(numberofports): #iterates through each port, 8-15 in final
                        poePower, time = getStatistics(jsonObject,1,'poePower')
                        temp =Averages[x][0]+(poePower-Averages[x][0])/(y+1) #rolling average calculation
                        Averages[x]=(temp, time)
        return (Averages)                       
def getPOEMaxes(jsonqueue):
        #timestamps = [0] * 8#not sure how to initialize list of timestamps want 
        #Maximums = [0] * 8
        print('max was called')
        Maximums =[(0,0)*numberofports]
        for y in range(numberiterations):
                print(y)
                jsonObject=jsonqueue.get()
                print('max should end')
                for x in range(numberofports): #iterates through each port, 8-15 in final
                        poePower, time= getStatistics(jsonObject,1,'poePower')
                        if poePower>Maximums[x][0]:
                                Maximums[x]=(poePower,time)
        
        return (Maximums)
def getPOEMins(jsonqueue):  
        #timestamps = [0] * 8#not sure how to initialize list of timestamps
        Minimums =[(150,0)*numberofports]
        #Minimums = [0] * 8
        #Minimums = [150 for i in range(8)]#assumes that no port will have a higher minimum then 150 watts
        for y in range(numberiterations):
                jsonObject=jsonqueue.get()
                for x in range(numberofports): #iterates through each port, 8-15 in final
                        poePower, time= getStatistics(jsonObject,1,'poePower')
                        if poePower<Minimums[x][0]: #compars and sets maximums and mins per port
                                Minimums[x]=(poePower,time)                    
        return (Minimums)
output:functions
functionqueue1= copy.copy(Queofjson)
print(getPOEAverages(functionqueue1))#there is definitly a way to set the functions to static
functionqueue= copy.copy(Queofjson)
print(getPOEMaxes(functionqueue))
output:
python3 main.py
[(0.96, 1657550520513)]
max was called
0

```

Things to do
- [ ] Fix bug that occures when passing queue to max function
- [ ] Fix Average value function so it doesn't just return the last timestamp it received
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits
- [ ] make function to return any specific value of a specific iteration given the full json que

### Week 8: 7/11 to 7/15 ###
#### Monday July 11th ####
- [ ] Talked with Raj, he wants: circular buffer, three threads that operate at smae time-> reading standard writing and intercetion writing, three variables to control-> the total time the function is active, the delay between occurances of reading as well as writing
- [ ] Wrote code for the three basic threads as separate functions
```
def Read(threadname, Queofjson):
def Dostuff(threadname, Queofjson):
        #global Queofjson
        while (time.time()-starttime)<Totaltime:
                if(Queofjson.qsize()==1):
                        print('there are 1 jsons')
                #print(len(Queofjson))
                time.sleep(execution_check)
def Write(threadname, Queofjson):
        while (time.time()-starttime)<Totaltime:
                #print('write called')
                timestamps=getquetimestamps()
                #print(timestamps)
                header = ['timestamps']
                Port1 = [timestamps]
                #header2 = ['what time started', 'started on', 'every time it changed', 'what it changed to each time']
                with open('edgeswitch.csv', 'w', encoding='UTF8') as f:
                        writer = csv.writer(f)
                        writer.writerow(header)
                        writer.writerow(Port1)
                time.sleep(frequency_write)       
```
- [ ] Created Cycling Queue system primarily within Read function
```
def Read(threadname, Queofjson):
        #global Queofjson
        while (time.time()-starttime)<Totaltime:
                
                #print('read called')
                with UnifiSwitchClient(
                        host='https://192.168.0.5',
                        username='ubnt',
                        password='why1not2') as client:
                        info = client.get_POE_info()
                if Queofjson.qsize()==numberiterations:#this makes the que circular might be unneeded due to maxlength
                         Queofjson.get()
                Timestamp=getTimestamp(json.dumps(info))
                testingtimestamp= Timestamp
                Queofjson.put(( Timestamp,json.dumps(info)))
                print(Queofjson.qsize())
                #print(Queofjson[-1])
                time.sleep(frequency_read)
```
- [ ] Changed the libraries used by Queue so as to allow the threads to act opon common variables
```
#import multiprocessing
from threading import Thread
import queue
```
- [ ] Added function to return respective timestamps for all jsons currently in que
```
def getquetimestamps():
        Timestamps= [0 for i in range(Queofjson.qsize())]
        temp=Queofjson.queue
        for x in range(Queofjson.qsize()):
                Timestamps[x], json = temp[x]
        print(Timestamps)
        return (Timestamps)
```
- [ ] Added funtion to return a json from Queue given its timestamp, this timestamp is currently automatically called
```
def getJson(Timestamp):
        temp=Queofjson.queue #this makes a copy of the given que in dque format which makes it possible to operate on its individual members
        for x in range(len(temp)):
                time, json=temp[x]
                if time>=Timestamp:#returns if timestamp is equal or has already been passed by iteration
                        return json 
        return ('error submitted timestamp too low')
```
output:
```
[]
1
there are 1 jsons
[1657577106639]
2
[1657577106639, 1657577108339]
2
[1657577108339, 1657577110282]
2
ending main
[{"timestamp": 1657577110282, "device":......
```


Things to do:
- [ ] Write code to improve getaverage() function to return timestamp of when output closest to average ocuured

#### Tuesday July 12th ####
- [ ] Talked with and provided demo of current process to Raj, 
he wants:
- [ ] login password removed from commited file and password changed in device
  - [ ] My solution: storing the password in a noncommited python file as a variable
```
 with UnifiSwitchClient(
                        host='https://192.168.0.5',
                        username='ubnt',
                        password=password.password) as client:#password is from another not included file
                        info = client.get_POE_info()
```
- [ ] Current main Python file broken up into multiple other files
  - [ ] Unfortunatly I ran into significant trouble trying to divide out the three threads into thier own file apart from main, with variables not passing themselves over and between the threads correctly, so for now the threethreads.py file is nonfuctional, instead the three threads are located within main.py
```
import threethread #haven't been able to get threading to talk with other 
#files well, so temporarily usless
'''error message
File "/home/isaiah/code/main.py", line 3, in <module>
    Queofjson= queue.Queue()#maxsize=buffer_length)
NameError: name 'queue' is not defined

'''
import statisticgetter
'''
#pp = pprint.PrettyPrinter(indent=2, width=30, compact=True) #read when pretty print is desired
#getStatistics(jsonObject,portnumber,variable):# ex: 3 'poePower'
#getRaminfo(jsonObject,variable):
#getTempinfo(jsonObject,area,variable):#area= 0-3, 
#getProcessorUsage(jsonObject):
#getUptime(jsonObject):
'''
import secondarys
'''
def getPOEAverages(jsonqueue):      
def getPOEMaxes(jsonqueue):
def getPOEMins(jsonqueue):  
'''
import password
```
- [ ] Initial plugin setup to publish to local filesystem
  - [ ] I eventually got the basic plugin to run without errors, but ran into problems getting input to download to the directory designated by:
```
 commmand line: env PYWAGGLE_LOG_DIR=/plugin-log

```
```
with Plugin() as plugin:
                        rightnow=time.time_ns()
                        #plugin.upload_file('edgeswitch.csv')#, timestamp=rightnow)
                        plugin.publish("plugin.log", 1234, timestamp=rightnow)#,timestamp=rightnow)
```
![image](https://user-images.githubusercontent.com/106760508/178788373-ae196cda-59f1-4948-9360-bc2245290393.png)
- [ ] His edits during demo commited into main file
  - [ ] Removed time limit set on threads so they continue until ended by keyboard input
  - [ ] Discovered my functions are reading miliseconds instead of seconds
```
 while True:
        #while (time.time()-starttime)<total_time:
```
- [ ] Recorded unkown popup that briefly covered my screen a few occasions
![image](https://user-images.githubusercontent.com/106760508/178789956-ab9e3120-4bec-4c88-b221-6973da52c761.png)
- [ ] Got basic plugin to run without errors, but ran into problems getting input to download to directory
- [ ] Notes on plugin
  - [ ] As beehive is currently not accessible, we have to test our code via pushes to local directories,
  - [ ] Although any local file that refernces waggle.plugin can run the necessary plublish functions, the documentation to be submitted to the edge database is somewhat extensive and is to be contained on Github

Things to do:
- [ ] Get threading to work in multiple files
- [ ] Write code to improve getaverage() function to return timestamp of when output closest to average ocuured
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits
- [ ] Look into possible sources of pop up to ensure it is not part of something malicious

#### Wednesday July 13th ####
- [ ] Attended mandatory meeting on how "on the lawn" and "off the lawn" will work
- [ ] Went outside due to fire drill
- [ ] Looked into white pop-up and confirmed it is part of the gnome network connectivity manager, which continued to fail as I do not actually have gnome installed
- [ ] Talked to Sean about how to publish data from the .py file my project is in
- [ ] Successfully published an arbitrary value
```
 with Plugin() as plugin:
                        rightnow=time.time_ns()
                        #plugin.upload_file('edgeswitch.csv')#, timestamp=rightnow)
                        plugin.publish("test.bytes", 1234, timestamp=rightnow)#,timestamp=rightnow)
                #can likly use 'edgeswitch' to publish edgeswitch contents
```                
![image](https://user-images.githubusercontent.com/106760508/179076564-2bf7df2e-88c6-4d05-a012-2b132ffd4c68.png)

- [ ] Talked to Sean about my code: he reccomended not using multiple threads
- [ ] Talked to Raj, he clarified the reasoning on why we need to use different reoccurring delays for each thread,also gave me a written version of previously expressed requirements
```
This is what we need in terms of capabilities:
We should be able to read and store in memory (transient/RAM/Variables) values that we can get from the Switch. These values should ideally be in the original form they were received and in full. Don't waste resources converting, don't loose data because we did not have a clear understanding of what it could be used for. Filtering can happen later. The read rate should be definable.
We should be able to write the raw values read to Beehive using pywaggle. We should also be able to write secondary digested values based on the buffer of values we have collected in our reading and buffering process. This can happen periodically, and we should be able to set the rate.
We should be able to catch when some event happens, and report it to beehive. The latency in detecting an event is ideally less that the latency of the periodic process. I.e. We may periodically report every 5 min, our buffer may be 10 min long, read every 1 second and want to report the events ASAP ( of course there is a latency Vs Performance trade off).
After having completed a single sequential loop, design a program that can do the above.
```
- [ ] Began reforming my code aroud a List of Jsons instead of a Queue, so as to avoid potential problems stemming from how I would have to access a value within the queue by altering the queue from multiple threads and functions    

Things to do:  
- [ ] Write code to improve getaverage() function to return timestamp of when output closest to average ocuured
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits
- [ ] Complete transformation of code to safer List focussed version
- [ ] Create functionality to make a graph of changes in a given value over a time period

#### Thursday July 14th ####
- [ ]  Finished reforming project to use a large list instead of a queue
```
if len(myconfig.Listofjson)==buffer_length:#this makes the que circular might be unneeded due to maxlen(myconfig.Listofjson)
                         myconfig.Listofjson.pop(0)
                dumpedjson=json.dumps(info)
                Timestamp=statisticgetter.getTimestamp(dumpedjson)
                myconfig.Listofjson.append(( Timestamp,dumpedjson))
                            
                

```
instead of having to make a copy which I wold then edit, I could now look directly at values that were within the Listofjsons
```
def getJson(Timestamp):
        for x in range(len(myconfig.Listofjson)):
                time, json=myconfig.Listofjson[x]
                #print(time, (time-Timestamp))
                if time>=Timestamp:#returns if timestamp is equal or has already been passed by iteration
                        break
        return json
```
- [ ]  Eliminated unnessary passed variables, instead referencing them within a new config file
```
def getPOEMaxes():
        Maximums =[(0,0)*myconfig.numberofports]
        for y in range(len(myconfig.Listofjson)):#I previously passed in a copy of the Que of Jsons
                print(y)
                jsonObject=myconfig.Listofjson[y]
                print('max should end')
                for x in range(myconfig.numberofports): #iterates through each port, 8-15 in final, I previously stored the number of ports locally
                        poePower, time= statisticgetter.getStatistics(jsonObject,1,'poePower')
                        if poePower>Maximums[x][0]:
                                Maximums[x]=(poePower,time)
        
        return (Maximums)
```
- [ ]  Hunted down a now unneeded print that originated from a statisticsgetters function, in the process re-discovering the 'find' command
```
def getTimestamp(jsonObject):
        data=json.loads(jsonObject)
        Timestamp=data[0]['timestamp']
        #print(Timestamp) #this is the offending print statement
        return(Timestamp)
```
- [ ]  Printed out a graph of poe values over the timeperiod contained within the buffer using a few new functions
```
def Getshortenedlist(firsttimestamp, secondtimestamp):
    shortlist =[]
    for i in range(len(myconfig.Listofjson)):
        timestamp, json= myconfig.Listofjson[i]
        if(timestamp>=firsttimestamp):
            shortlist.append((timestamp, json))
        if(timestamp>secondtimestamp):
            break
    return(shortlist)
def getStatisticPlot(variable, port, firsttimestamp, secondtimestamp):
    shortlist=Getshortenedlist(firsttimestamp, secondtimestamp)
    Timestamps=[0]*len(shortlist)
    Poes=[]
    values=[0]*len(shortlist)
    for x in range(len(shortlist)):
        Timestamps[x], json = shortlist[x]
        values[x], othertimestamps=statisticgetter.getStatistics(json,port,variable)
    print(Timestamps)
    print(values)
    plt.plot(Timestamps, values)
    plt.xlabel('Timestamps')
    plt.ylabel('variable')
    plt.title('variable Vs Time')
    plt.show()
def getPlotofbufferStatistic(variable, port):
    Listoftimestamps=getlisttimestamps()
    firsttimestamp=Listoftimestamps[0]
    lasttimestamp=Listoftimestamps[-1]
    getStatisticPlot(variable, port, firsttimestamp, lasttimestamp)
def getlisttimestamps():
        Timestamps= [0 for i in range(len(myconfig.Listofjson))]
        for x in range(len(myconfig.Listofjson)):
                Timestamps[x], json = myconfig.Listofjson[x]
        return (Timestamps)
```
here is an example plot of the change in poe power draw from a dummy device over 29 iterations, which repersents roughly a 1 minute 
![image](https://user-images.githubusercontent.com/106760508/179082793-b77a4f80-8952-4a3a-af89-80c9af90f51e.png)

Things to do: 
- [ ] Write code to improve getaverage() function to return timestamp of when output closest to average ocuured
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits

#### Friday July 15th ####
- [ ] Talked with Sean over slack about implementing a safer threading system that uses a double que system, so writing and interjection threads don't get in each others way
- [ ] Assisted Raj with splitting a SAGE node into two for testing purposes
- [ ] Combined various getter functions that would retrieve values from jsons, so that there are only two function calls, that rely on the variable name called to choose between different indexing outputs
```
def withIndexGetter(jsonObject, index, variable):
        data=json.loads(jsonObject)
        if(variable=='name' or variable=='value' or variable=='type'):#this triggers if temperature info is requested, max index of 3
                value=data[0]['device']['temperatures'][index][variable]
                variable='temperature info'+ variable
                indexstring= 'area:'+str(index)
        else:  #variable= dropped errors txErrors rxErrors rate txRate rxRate bytes txBytes rxBytes packets txPackets rxPackets pps txPPS rxPPS poePower
              value=data[0]['interfaces'][index]['statistics'][variable]#this triggers if ports information is requested, port= 0-15
              indexstring= 'port:'+str(index+1)  
        return(variable, indexstring, value)

def noIndexGetter(jsonObject, variable):
        data=json.loads(jsonObject)
        if(variable=='timestamp'):# if the variable requested is timestamp
                value=data[0]['timestamp']
        elif(variable=='uptime'):
                value=data[0]['device']['uptime']
        elif(variable=='processor usage'):
                value=data[0]['device']['cpu'][0]['usage']
        elif(variable=='usage' or variable=='free' or variable=='total'):#if ram information is requested
                value=data[0]['device']['ram'][variable]#variable = usage, free, total
                variable='ram '+variable# this makes the requested variable clear in read out
        else:
                print("variable not correct")
        return(variable, value)

```
- [ ] These two getters divide what values they retreive based on whether the values they retrieve requires an index, ie port or area number
```
noIndexGetter(jsonObject, variable): vs withIndexGetter(jsonObject, index, variable)
```
- [ ] These functions now return the name of the variable they retrieved, inthe case of the index function a string containing the type of index used as well as its value, and the value itself that was retreived
```
else:  #variable= dropped errors txErrors rxErrors rate txRate rxRate bytes txBytes rxBytes packets txPackets rxPackets pps txPPS rxPPS poePower
              value=data[0]['interfaces'][index]['statistics'][variable]#this triggers if ports information is requested, port= 0-15
              indexstring= 'port:'+str(index+1)  
        return(variable, indexstring, value)
```
- [ ] Implemented the double que system that Sean reccomended
```
writer_queue =Queue()
        Thread(target=Write, args=(myconfig.frequency_write, writer_queue,), daemon=True).start()
        
        trigger_queue =Queue()
        Thread(target=Trigger, args=(myconfig.execution_check, myconfig.buffer_length, trigger_queue,), daemon=True).start()

        Read(myconfig.frequency_read,[writer_queue, trigger_queue])
```
- [ ] Added functionality to retrieve poe values for each port, which now include a variety of devices, and print them into a csv
```
in thread:
for i in range(myconfig.numberofports):
                                variablecalled, indexstring, value= statisticgetter.withIndexGetter(jsonobject, i,'poePower')# return(Statistic,data[0]['timestamp'], portnumber, variable, 'basicstatis')
                                pair= str(timestamp), variablecalled, indexstring, str(value) 
                                #isdropped, indexstring, value= statisticgetter.withIndexGetter(jsonobject, i,'dropped')# return(Statistic,data[0]['timestamp'], portnumber, variable, 'basicstatis')
                                #print(isdropped, indexstring)
                                stringoutput=','.join(pair)
                                
                                with open('edgeswitch.csv', 'a', encoding='UTF8') as f:
                                        writer = csv.writer(f)
                                        writer.writerow(pair)
                                                      
```
```
1657928912618,poePower,port:1,2.57
1657928912618,poePower,port:2,2.67
1657928912618,poePower,port:3,2.14
1657928912618,poePower,port:4,0.0
1657928912618,poePower,port:5,13.62
1657928912618,poePower,port:6,0.0
1657928912618,poePower,port:7,4.33
1657928912618,poePower,port:8,2.57
```
- [ ] Ran program over the weekend with adjusted write and read rates to create enough data to run other tests

Things to do:
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits

### Week 9: 7/18 to 7/22 ###
#### Monday July 18th ####
- [ ] Did Friday daily journal
- [ ] Made short list of what variabes we should be checking in our interuption thread
  - [ ] processor usage
  - [ ] total errors
  - [ ] per area temperature values
  - [ ] ram total
  - [ ] ram free
  - [ ] POE
  - [ ] uptime  
- [ ] Made short function to test for drastic changes between two values, in practice these values will belong to neighboring retreived json files, comparing them will enable the function to interject when an event takes place that greatly alters said value
```
def isnormalcheck(variable, standardvalue, currentvalue):#later add in details on acceptable ratio
        if standardvalue== 0 and currentvalue==0:
                proportion=1
        elif standardvalue== 0:
                proportion= 3*currentvalue
        else: proportion=currentvalue/standardvalue
        if(proportion>1.5):
                return(variable,"raised is now this fraction of former value:",proportion)
        elif(proportion<0.75):
                return(variable,"dropped is now this fraction of former value:",proportion)
        else: return None
```
- [ ] Implemented said function in the interupt thread to detect whether two most recent jsons objects in dequeue contain very different Poe values
``` if(len(buffer)>2):
                    currenttimestamp, currentjsonobject=buffer[-1]
                    #print(currentjsonobject)
                    pasttimestamp, pastjsonobject=buffer[-2]
                    #print(pastjsonobject)
                    for i in range(myconfig.numberofports):
                            POEvariable, indexstring, currentvalue= statisticgetter.withIndexGetter(currentjsonobject, i,'poePower')# return(Statistic,data[0]['timestamp'], portnumber, variable, 'basicstatis')
                            #print(currentvalue, i)
                            POEvariable, indexstring, pastvalue= statisticgetter.withIndexGetter(pastjsonobject, i,'poePower')
                            normalcheck=secondarys.isnormalcheck(POEvariable, pastvalue, currentvalue)
                            #if i==3:
                                #print(currentvalue, pastvalue)
                            if normalcheck is not None:
                                print(currenttimestamp,indexstring, normalcheck)#return(variable,"dropped is now this fraction of former value:",proportion)
sample output:
updated trigger buffer
updated trigger buffer
updated trigger buffer
1658168108394 port:1 ('poePower', 'dropped is now this fraction of former value:', 0.0) <----port refreshed here
updated trigger buffer
1658168110234 port:1 ('poePower', 'raised is now this fraction of former value:', 4.71) <----port returns to original value here


```
- [ ] Implemented function to tell if uptime goes down, which would mean switch restarted
```
                  if (len(buffer)==1):
                        firsttimestamp, firstjsonobject=buffer[0]
                        originaluptime=statisticgetter.noIndexGetter(firstjsonobject, 'uptime')

                elif(len(buffer)>1):
                        currenttimestamp, currentjsonobject=buffer[-1]
                        pasttimestamp, pastjsonobject=buffer[-2]
                        currentuptime=statisticgetter.noIndexGetter(currentjsonobject, 'uptime')
                        if(currentuptime < originaluptime):#there might be a problem with this implemetation not triggering becuase too much delay
                                print(currenttimestamp, "the switch has restarted")
                                originaluptime=currentuptime           
```
- [ ] Revised method of testing for events so now each iterations values are tested against either the first readings or the last time the value was detected as being substantually different, this way total change can be tested against instead of change since last iteration
                
```
if (len(buffer)==1): #this provides the first values submitted into the que which will be the original values compared against
         firsttimestamp, comparingjsonobject=buffer[0]
         comparinguptime=statisticgetter.noIndexGetter(comparingjsonobject, 'uptime')
         """
         noIndexGetter(jsonObject, variable):
         variable= 'timestamp' 'uptime' 'processor usage'):
         'usage' or 'free' or 'total'):(ram)
         return(variable, value)
         """
         for i in range(myconfig.numberofports):
               POEvariable, indexstring, originalvalue= statisticgetter.withIndexGetter(comparingjsonobject, i,'poePower')
               reviousvalues[i]= originalvalue              
```
```
elif(len(buffer)>1):
        currenttimestamp, currentjsonobject=buffer[-1]
        currentuptime=statisticgetter.noIndexGetter(currentjsonobject, 'uptime')
                      
        if(currentuptime < comparinguptime):#there might be a problem with this implemetation not triggering becuase too much delay
                  print(currenttimestamp, "the switch has restarted")
                  comparinguptime=currentuptime                      
                        
                  for i in range(myconfig.numberofports):
                             POEvariable, indexstring, currentvalue= statisticgetter.withIndexGetter(currentjsonobject, i,'poePower')
                             normalcheck=secondarys.isnormalcheck(POEvariable, previousvalues[i], currentvalue)
                             #return(variable,"dropped is now this fraction of former value:",proportion)
                  if normalcheck is not None:
                             print(currenttimestamp,indexstring, normalcheck)
                             previousvalues[i]=currentvalue             
```
sample output:
```
updated trigger buffer
updated trigger buffer
1658178469525 port:2 ('poePower', 'dropped is now this fraction of former value:', 0.0)
updated trigger buffer
updated trigger buffer
1658178473150 port:2 ('poePower', 'raised is now this fraction of former value:', 4.47)
updated trigger buffer
updated trigger buffer
updated trigger buffer
updated trigger buffer
updated trigger buffer
updated trigger buffer 
1658178484474 port:2 ('poePower', 'raised is now this fraction of former value:', 1.5436241610738255) <---- this incerease was previously undetected
updated trigger buffer
updated trigger buffer
```                 
- [ ]  


Things to do:
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits

#### Tuesday July 19th ####
- [ ] Added functionality to test for temperature, rate and error changes
```
             previouspoes= [0]*myconfig.numberofports
             previousTemps= [0]*myconfig.numberofareastemp #need to do over temp areas
             previousRates= [0]*myconfig.numberofports
             previousErrors= [0]*myconfig.numberofports
                          
                          #this is where the presetting of comparison variables takes place
                          
                          for i in range(myconfig.numberofports):
                                Ratevariable, indexstring, originalvalue= statisticgetter.withIndexGetter(comparingjsonobject, i,'rate')
                                previousRates[i]= originalvalue
                                POEvariable, indexstring, originalvalue= statisticgetter.withIndexGetter(comparingjsonobject, i,'poePower')
                                previouspoes[i]= originalvalue
                                
                                Errorsvariable, indexstring, originalvalue= statisticgetter.withIndexGetter(comparingjsonobject, i,'errors')
                                previousErrors[i]= originalvalue
                        for i in range(myconfig.numberofareastemp):
                                Tempvariable, indexstring, originalvalue= statisticgetter.withIndexGetter(comparingjsonobject, i,'value')
                                previousTemps[i]= originalvalue      
                        
                      #this is where I compare current values of the variables against the comparison values
                      
                        
                   elif(len(buffer)>1):
                        currenttimestamp, currentjsonobject=buffer[-1]
                        currentuptime=statisticgetter.noIndexGetter(currentjsonobject, 'uptime')
                      
                        if(currentuptime < comparinguptime):#there might be a problem with this implemetation not triggering becuase too much delay
                                print(currenttimestamp, "the switch has restarted")
                                comparinguptime=currentuptime                      
                        for i in range(myconfig.numberofareastemp):
                                Tempvariable, indexstring, currentTemp= statisticgetter.withIndexGetter(currentjsonobject, i,'value')
                                normalcheck=secondarys.isnormalcheck('temperature', previousTemps[i], currentTemp)#return(variable,"dropped is now this fraction of former value:",proportion)
                                #print(currentTemp, i)
                                
                                if normalcheck is not None:
                                        print(currenttimestamp,indexstring, normalcheck)
                                        previousTemps[i]=currentTemp
                                        
                        for i in range(myconfig.numberofports):
                                
                                Ratevariable, indexstring, currentRate= statisticgetter.withIndexGetter(currentjsonobject, i,'rate')                            
                                normalcheck=secondarys.isnormalcheck('rate', previousRates[i], currentRate)#return(variable,"dropped is now this fraction of former value:",proportion)
                                if normalcheck is not None:
                                        #print("pps recorded as", normalcheck)
                                        print(currenttimestamp,indexstring, normalcheck)
                                        string=currenttimestamp,indexstring,normalcheck
                                        if i==5:print("comparison rate should change")
                                        previousRates[i]=currentRate
                                        secondarys.RecordBigChanges(string)
                                        
                                
                                POEvariable, indexstring, currentPoe= statisticgetter.withIndexGetter(currentjsonobject, i,'poePower')
                                normalcheck=secondarys.isnormalcheck('poePower', previouspoes[i], currentPoe)#return(variable,"dropped is now this fraction of former value:",proportion)
                                if normalcheck is not None:
                                        print(currenttimestamp,indexstring, normalcheck)
                                        string=currenttimestamp,indexstring,normalcheck
                                        secondarys.RecordBigChanges(string)
                                        previouspoes[i]=currentPoe
                                Errorsvariable, indexstring, currentErrors= statisticgetter.withIndexGetter(currentjsonobject, i,'errors')
                                normalcheck=secondarys.isnormalcheck('errors', previousErrors[i], currentErrors)#return(variable,"dropped is now this fraction of former value:",proportion)
                                if normalcheck is not None:
                                        print(currenttimestamp,indexstring, normalcheck)
                                        previousErrors[i]=currentErrors



sample output:
when buffer is 55 Rate is 106408 compared rate is 135024
updated trigger buffer
when buffer is 56 Rate is 106408 compared rate is 135024
updated trigger buffer
1658263217176 port:1 ('rate', 'dropped is now this fraction of former value:', 0.2323943661971831)
1658263217176 port:1 ('poePower', 'dropped is now this fraction of former value:', 0.0)
1658263217176 port:4 ('rate', 'dropped is now this fraction of former value:', 0.14842578710644677)
when buffer is 57 Rate is 51392 compared rate is 135024
updated trigger buffer

```
- [ ] Fixed numerous bugs in first implemenatation, which included: unchanging comparison values for numerous variables, wrong variables sometimes getting passed to display functions
- [ ] Added a new function to display values from interjection thread in new csv file
```
def RecordBigChanges(change): 
        with open('bigchanges.csv', 'a', encoding='UTF8') as f:
                writer = csv.writer(f)
                writer.writerow(change)

sample output:
1658263274531,port:1,"('rate', 'dropped is now this fraction of former value:', 0.28314606741573034)"
1658263274531,port:3,"('rate', 'dropped is now this fraction of former value:', 0.28125)"
1658263274531,port:4,"('rate', 'dropped is now this fraction of former value:', 0.31777777777777777)"
1658263296152,port:4,"('rate', 'dropped is now this fraction of former value:', 0.32867132867132864)"
1658263356736,port:1,"('rate', 'raised is now this fraction of former value:', 6.238095238095238)"
1658263356736,port:3,"('rate', 'raised is now this fraction of former value:', 6.238095238095238)"
1658263356736,port:4,"('rate', 'raised is now this fraction of former value:', 16.76595744680851)"
1658263370772,port:1,"('rate', 'dropped is now this fraction of former value:', 0.2862595419847328)"
1658263370772,port:3,"('rate', 'dropped is now this fraction of former value:', 0.2862595419847328)"
1658263370772,port:4,"('rate', 'dropped is now this fraction of former value:', 0.28553299492385786)"
1658263389999,port:1,"('rate', 'dropped is now this fraction of former value:', 0.31555555555555553)"
1658263389999,port:3,"('rate', 'dropped is now this fraction of former value:', 0.32)"
1658263389999,port:4,"('rate', 'dropped is now this fraction of former value:', 0.31555555555555553)"



```
- [ ] Gave demo of progress to Raj
Things to do:
- [ ] Add previous WisGate work to Github
- [ ] Link up local repo for easy commits

#### Wednesday July 20th ####
- [ ] Talked with Raj, he wants: to be able to connect and disconnect switch while program is running, removal of various text in some outputs, in favor of just numbers, constant rolling tuple per port that gives current POE and whether it is connected and sendng data to switch, readouts whenever something loses or gains power or data connection
- [ ] I made a new list of (number of port) able lists, which will store the current POE and whether data is being recieved from the given port
```
 connectionStatus= [[0,'off'] for i in range(myconfig.numberofports)]#poe wattage, whether port is currently receiving data
             pastPOEstatus= ['off']*myconfig.numberofports
             connectionComparer= ['off','off']
- [ ] Changed testing code to focus on rxRate and POE,
                if (len(buffer)!=0):
                        currenttimestamp, currentjson=buffer[-1]
                        for i in range(myconfig.numberofports):
                                Ratevariable, indexstring, currentrxRate= statisticgetter.withIndexGetter(currentjson, i,'rxRate')                            
                                if currentrxRate== 0:
                                        connectionComparer[1]='off'
                                else:
                                        connectionComparer[1]='on'
                                POEvariable, indexstring, currentPOE= statisticgetter.withIndexGetter(currentjson, i,'poePower')                            
                                if currentPOE== 0:
                                        connectionComparer[0]='off'
                                else:
                                        connectionComparer[0]='on'
                                if connectionComparer[1] is not connectionStatus[i][1]:
                                        print(currenttimestamp,i+1,"connection changed connection is now ", connectionComparer[1])
                                        connectionStatus[i][1]=connectionComparer[1]                              
                                if connectionComparer[0] is not pastPOEstatus[i]:
                                        print(currenttimestamp,i+1,'POE changed POE is now', connectionComparer[0])
                                        """
                                                string=currenttimestamp,indexstring,normalcheck
                                                if i==5:print("comparison rate should change")
                                                secondarys.RecordBigChanges(string)
                                        """
                                        pastPOEstatus[i]=connectionComparer[0]
                                connectionStatus[i][0]=currentPOE


```


```
updated trigger buffer
1658351975058 1 POE changed POE is now on
1658351975058 3 POE changed POE is now on
1658351975058 4 connection changed connection is now  on
1658351975058 4 POE changed POE is now on
1658351975058 6 connection changed connection is now  on
1658351975058 8 POE changed POE is now on
readstarted
```


- [ ] Removed previous code which references testifnormal function
- [ ] Added try clause to catch switch disconnections
```
                try:
                        with UnifiSwitchClient(
                                host='https://192.168.0.5',
                                username='ubnt',
                                password=password.password) as client:#password is from another not included file
                                info = client.get_statistic_info()
                                dumpedjson=json.dumps(info)
                                #print(dumpedjson) 
                                variabletype, timestamp=statisticgetter.noIndexGetter(dumpedjson, 'timestamp')#gets timestamp from within json
                                for queue in queues:
                                        queue.put((timestamp, dumpedjson))
                                endtime=time.time()
                                if (frequency_read-(endtime-starttime))>0:     
                                        time.sleep(frequency_read-(endtime-starttime))
                except:
                        print("warning! switch not connected!")
                        endtime=time.time()
                        if (30-(endtime-starttime))>0:     
                                time.sleep(frequency_read-(endtime-starttime))


```

```
sample output:
updated trigger buffer
readstarted
updated trigger buffer
readstarted
updated trigger buffer
warning! no switch data!
updated trigger buffer
warning! no switch data!
warning! switch not connected!
readstarted
updated trigger buffer
readstarted
updated trigger buffer
readstarted
```

- [ ] Adjusted time.sleep() functionality to take into account time take to run thread
```
         endtime=time.time()
         if (execution_check-(endtime-starttime))>0:     
                    time.sleep(execution_check-(endtime-starttime))
```
#### Thursday July 21th ####
- [ ] Talked to Raj, he wants: every event monitored variable to be tested in terms of user set boundaries, for all responce statements to be sent to plugin directory rather than printed, writing thread to send most recent json every time it is triggered
- [ ] Created List of dictionaries in config file that allows for setting boundaries for each variable for each port
```
variableboundaries = [ {'value': (0,0), 'poePower':(1,50),'rxRate':(0,100)},#value refers to temp, port 1 (lowerboundary,upperboundary)
{'value': (50,80), 'poePower':(1,50),'rxRate':(0,100)},#port 2 or area2 depending on whether checking temp or ports
{'value': (100,500), 'poePower':(0,50),'rxRate':(0,7000)},
{'value': (0,0), 'poePower':(0,50),'rxRate':(0,7000)},
{'poePower':(0,50),'rxRate':(0,100)},#there are only 4 areas temperatures that can be read
{'poePower':(0,50),'rxRate':(0,100)},
{'poePower':(0,50),'rxRate':(0,100)},
{'poePower':(0,50),'rxRate':(0,5000)}
]
```
- [ ] Created systyem of cycling through previous List while comparing current values by using some complicated iteration and calling a newly created function
```
within main function:
for i in range(8):#number of iterations not adjustable upwards as it is reliant on boundaries set in config
       Ratevariable, indexstring, currentrxRate= statisticgetter.withIndexGetter(currentjson, i,'rxRate')                         
       for key in myconfig.variableboundaries[i]:
             currentvalue=statisticgetter.withIndexGetter(currentjson, i, key)[2]#[2] is becuase statisticgetters return tuples beyond just the value
             check=secondarys.isnormalcheck(key, i, currentvalue)
             if(check!=None):#check= low if below boundaries, high if above
                        pair= str(i+1), key, check 
new function:
def isnormalcheck(variable, index, currentvalue):
        lowerboundary, upperboundary=myconfig.variableboundaries[index][variable]
        if(currentvalue>upperboundary):
                return("High")
        elif(currentvalue<lowerboundary):
                return("Low")
        else: return(None)
```
- [ ] Spent roughly an hour cleaning code and making previously created but now unused functions presentable
- [ ] Created and tested method of sending printouts to local directory
```
 pair= str(i+1), key, check 
 stringoutput=','.join(pair)
 with Plugin() as plugin:
      timestamp =time.time_ns()#if uncommented, plugin will be sent current time as timestamp rather than the timestamp of the json
      plugin.publish("test.bytes", stringoutput, timestamp=timestamp)
      if key!= 'value':
              plugin.publish("test.bytes", str(connectionStatus[i]), timestamp=timestamp)

sample output:

{"name":"test.bytes","ts":1658442205804326588,"meta":{},"val":"1,value,High"}
{"name":"test.bytes","ts":1658442206812179926,"meta":{},"val":"3,value,Low"}
{"name":"test.bytes","ts":1658442207824764287,"meta":{},"val":"4,value,High"}
{"name":"test.bytes","ts":1658442208840983822,"meta":{},"val":"8,rxRate,High"}
{"name":"test.bytes","ts":1658442208840983822,"meta":{},"val":"[0.0, 'on']"}
{"name":"test.bytes","ts":1658442210858644724,"meta":{},"val":"1,value,High"}
{"name":"test.bytes","ts":1658442211872862993,"meta":{},"val":"3,value,Low"}
{"name":"test.bytes","ts":1658442212891783477,"meta":{},"val":"4,value,High"}
{"name":"test.bytes","ts":1658442213900134846,"meta":{},"val":"8,rxRate,High"}
{"name":"test.bytes","ts":1658442213900134846,"meta":{},"val":"[0.0, 'on']"}


```
- [ ] Added a variable to config that allows user control over what rxRate classifies a port as off 

Things to do: 
- [ ] Set error and warning messages so they are sent to directory 
- [ ] Talk to Sean about what format to send information in and image processing responsibilitys
- [ ] Work on code annotations and readme
- [ ] Work on SULI end deliverables
- [ ] Give credit to source of ubnt in readme 
- [ ] Present demo of working system to Raj
- [ ] Create sytem to accept blank boundaries as ignored values
- [ ] Figure out timestamp problem that prevents plugin from accepting json's timestamp

#### Friday July 22th ####
- [ ] Helped Raj manage and inventory some mail in parts
- [ ] Changed boundary values so there are no warnings in normal state
- [ ] Upgraded README to current project, adding pictures and examples when helpful
- [ ] Uploaded previous WisGate progress to GitHub
- [ ] Gave demo of progress to Raj
- [ ] Changed rxRate checks to rate, after Raj indicated he wanted any connection where data was sent but not received to still register as a full connection
- [ ] Took notes on Waggle Github slides to see if I could find anything not said that should be said in order to explain the project to someone who knew nothing of the project

Things to do:
- [ ] Begin readying SULI end deliverables
- [ ] Go through READMEs with family and friends to try to do final editing
### Week 10: 7/25 to 7/29 ###
#### Monday July 25th ####
- [ ] Touched up READMEs
- [ ] Assigned Project to get data from Sage related camera
- [ ] Found command to do above, failed in implementation 
- [ ] Helped Raj solder on ports for Waggle
- [ ] Helped Raj test a new AC converter which could possible be used by the SAGE node, unfortunatley the converter continued to fail to successfully accept DC and convert the power so it could be used by a sample SAGE node

Things to do:
- [ ] Go through and edit past daily logs
- [ ] Get video puller working
#### Tuesday July 26th ####
- [ ] Caught up on previous daily logs
- [ ] Set password of camera to something without wildcard characters that throw off requests
- [ ] Attended student connection group to practice speaking on my the work I did this summer
- [ ] Read through WiseNet documents, the most important of which is SUNAPI: Application Programmer's Guide, and is stored in the relevant project folder
- [ ] Performed more tests with Raj on AC converter, learened that it requires very high starting current that regular power sources cannot provide
- [ ] Discovered a reccomended "time" notation in the relevant documentation which I used in my tests
```
The time should be specified in the following format:
<YYYYMMDDTHHMMSS> (e.g, 20141206T111500) for local time and
<YYYYMMDDTHHMMSSZ>
(e.g, 20141206T110000Z) for UTC time.
```
- [ ] Discovered how to use password and username in rtsp commands so as to pass authorization 
```
mpv "rtsp://username:password@10.31.81.10/recording/play.smp"
```
- [ ] Tested each "playback" video command to see which one I should focus on trying to get work
```
Camera URL format:
[Type1]
rtsp://<Device IP>/recording/<Start Time>/play.smp <--- returned 404 not found
[Type2]
rtsp://<Device IP>/recording/<Start Time>-<End Time>/play.smp<--- returned 404 not found
[Type3]
rtsp://<Device IP>/recording/play.smp<--- returned 501 'Play' :Not implemented
Camera URL format (multi source device)
[Type1]
rtsp://<Device IP>/<chid>/recording/<Start Time>/play.smp<--- returned 404 not found, (I used "0" for "chid")
[Type2]
rtsp://<Device IP>/<chid>/recording/<Start Time>-<End Time>/play.smp<--- returned 404 not found
[Type3]
rtsp://<Device IP>/<chid>/recording/play.smp<--- returned 501 'Play' :Not implemented
NVR URL format
[Type1]
rtsp://<Device IP>:558/PlaybackChannel/<chid>/media.smp<--- returned 404 not found, (I used 554 as port as that is the port my camera uses)
[Type2]
rtsp://<Device IP>:558/PlaybackChannel/<chid>/media.smp/session=<sid><--- returned 404 not found (I used 0 for session id)
[Type3]
rtsp://<DeviceIP>:558/PlaybackChannel/<chid>/media.smp/overlap=<id>&session=<sid><--- returned 404 not found
```
Note: only the commands with 501 errors showed "unauthorized" errors when the password was not correct

- [ ] Explored UI for settings that were related to "playback" function, discovered a setting that should allow for connections to not require authentication, though I eventually realized that this setting only related to live view
![image](https://user-images.githubusercontent.com/106760508/181582350-52f262da-c51d-4a33-be0a-72fa8426795f.png)
Things to do:
- [ ] Discover why authentication still required despite having changed related setting in UI
- [ ] Go through and edit past daily logs
- [ ] Get video puller working
#### Wednesday July 27th ####
- [ ] Retested previously tested commands, received same results
- [ ] Learned that there is probaly a problem with my method of denoting timestamps because any command where I use them is not recognised by device, in this case by recognized I mean that changing the password provokes an unauthorized error
```
EX:
rtsp://<Device IP>/recording/play.smp-->recognized
rtsp://<Device IP>/recording/<Start Time>/play.smp-->not recognized
```
- [ ] Attended Weekly Lecture, this time on the work that is being done to predict and counter natural disasters 
- [ ] Began to test other related HTTP url commands, using browser because my ubuntu installation was no longer supported and had an outdated installation of some process related to opening the urls
- [ ] Discovered a bunch of device info by trying all related commands
```
for example:
http://<Device IP>/stw-cgi/system.cgi?msubmenu=deviceinfo&action=view

returns:
Model=XNV-8080R
SerialNumber=ZG996V4R1000CBK
FirmwareVersion=2.10.02_20220401_R615
BuildDate=2022.04.01
WebURL=http://www.hanwha-security.com/
DeviceType=NWC
ConnectedMACAddress=E4:30:22:2B:2A:F5
ISPVersion=1.60_211007
BootloaderVersion=       
CGIVersion=2.6.0
ONVIFVersion=20.12
DeviceName=Camera
DeviceLocation=top
DeviceDescription=Super Camera
Memo=Memo
Language=English
PasswordStrength=Strong
OpenSDKVersion=4.02_220126
FirmwareGroup=XND-8080R
```
- [ ] As I was testing other URL based commands, I noticed that most of them refer to the "STW" format offered as a video storage option by the camera, I reformatted the sd card using the new format, but after observing no changes in results I eventually returned the format to "AVI"
<br>

![image](https://user-images.githubusercontent.com/106760508/181581772-f5460ecb-b42d-4292-893a-2a0991f28c15.png)

- [ ] Confirmed that the NVR related commands will not work becuase they are designed to interact with a central computer that runs multiple cameras
- [ ] With Raj:
  - [ ] Updated firmware on camera
  - [ ] Re-installed xubuntu on loaned laptop to a newer version
  - [ ] Learned that cameras will accept timestamps in a format that refers to universal time without the "T" the timestamps references I previously used had, this indicates the documents are outdated
```
mpv "rtsp://username:password@10.31.81.10/recording/20220727225200Z/play.smp"
results in:
[ffmpeg/demuxer] rtsp: Could not find codec parameters for stream 0 (Video: mjpeg, none(bt470bg/unknown/unknown)): unspecified size
[ffmpeg/demuxer] Consider increasing the value for the 'analyzeduration' (0) and 'probesize' (5000000) options

```
Things to do:
- [ ] Go through and edit past daily logs
- [ ] Get video puller working by looking into errors that occure when using new timestamp notation
#### Thursday July 28th ####
- [ ]   Updated Daily logs
- [ ]   Logged into new xubuntu install with slack, Github, outlook
- [ ]   Expanded on previous day's progress with new timestamp format
- [ ]   Looked into what requests the UI makes when it exports footage, in the process learning that it always uses NVR format for all calls, which doesn't translate well over to command line 
- [ ]   Discovered that the footage is not throwing any errors when requested with new timestamp format, and so likley the problem has somthing to do with the final playing of the video
```
[ffmpeg/demuxer] rtsp: Could not find codec parameters for stream 0 (Video: mjpeg, none(bt470bg/unknown/unknown)): unspecified size
[ffmpeg/demuxer] Consider increasing the value for the 'analyzeduration' (0) and 'probesize' (5000000) options
[ffmpeg/demuxer] rtsp: Could not find codec parameters for stream 2 (Video: hevc, none): unspecified size
[ffmpeg/demuxer] Consider increasing the value for the 'analyzeduration' (0) and 'probesize' (5000000) options
 (+) Video --vid=1 (mjpeg)
     Video --vid=2 (h264 2560x1920)
     Video --vid=3 (hevc)
 (+) Audio --aid=1 (pcm_mulaw 1ch 8000Hz)
     Audio --aid=2 (adpcm_g726le 1ch 8000Hz)
     Audio --aid=3 (adpcm_g726le 1ch 8000Hz)
     Audio --aid=4 (adpcm_g726le 1ch 8000Hz)
     Audio --aid=5 (adpcm_g726le 1ch 8000Hz)
     Audio --aid=6 (aac 1ch 16000Hz)
File tags:
 Comment: samsung
 Title: Media Presentation

```
- [ ]   Found that I can play the footage with ffplay
```
ffplay rtsp://admin:why1not+@10.31.81.10/recording/20220729083000Z/play.smp

```

- [ ]   Made README for camera project
- [ ]   Collected info from Andre that will hopefully allow me to get the WisGate up and running with its own LoRa devices


Things to do: 
- [ ] Go through and edit past daily logs
- [ ] Get WisGate up and running 
#### Friday July 29th ####
- [ ] Learned from Raj that WisGate implementation was now unneeded
- [ ] Worked on outline for presentation and research paper
- [ ] Talked with Sean about bug where queues passed to threads will slowly fall behind Read thread due to frequency differences: decided I should ask Raj is I should implement a stack instead of a que or ditch wait times altogether
- [ ] Raj said that I need to keep wait times in place, thus I need to alter the implemented queue system
- [ ] I fixed the ubnt file to include the renamed statistic_getter method
- [ ] Created a altered main.py file that changes two independant couples as way of passing JSONs between threads
```
 myconfig.writeitem=(timestamp,dumpedjson)
 myconfig.triggeritem=(timestamp,dumpedjson)
 print(timestamp)
 #for queue in queues:
     #queue.put((timestamp, dumpedjson))
```
- [ ] Created a altered Quemain.py file that keeps the number of items in the queues at 1  
```
 for queue in queues:
      if queue.qsize()!=0:
          queue.get()
      queue.put((timestamp, dumpedjson))
```


Things to do:
- [ ] Make presentation

### Week 11: 8/1 to 8/5 ###
#### Monday August 1st ####
- [ ] Received pointers on presentation from Raj, he reccomended I shrink the number of slides about the MILAN project and add slides about the camera project
- [ ] Altered presentation acording to Raj's specifications
- [ ] Updated previous GitHub READMEs and caught up daily logs
- [ ] Recorded and uploaded presentation to both SULIs site and the box folder where we were told to submit
- [ ] Completed detailed outline of paper, 1000 out of currently 2000 words

Things to do:
- [ ] Finish Research paper
- [ ] Go through and edit past daily logs
- [ ] Look into how to return camera settings to normal from a reset
#### Tuesday August 2nd ####
- [ ] Finished first draft of research paper
- [ ] Made improvements to presentation
- [ ] Spoke to Raj about what kind of reset he wanted me to be able to return the Camera from, he wants to be able to return the camera from a total factory reset, he reccommended finding some way to download the config file then reupload it after factory reset
- [ ] Looked through documentation and found no way to touch the config file, Raj reccomended I poke Yongho about getting access to the repo where they have a script to initialize the camera, I could just add record initialization there
- [ ] Yongho was poked 

Things to do:
- [ ] Finish Research paper
- [ ] Go through and edit past daily logs
- [ ] Look into getting access to the repo
#### Wednesday August 3rd ####
- [ ] Practiced for final presentation
- [ ] Gave final presentation
- [ ] Edited Research paper with feedback from people asked
- [ ] Updated Daily logs
- [ ] Got access to repo from Yongho
- [ ] Took exit survey
- [ ] Wrote and submitted general audience abstract

Things to do:
- [ ] Finish Research paper
- [ ] Go through and edit past daily logs
- [ ] Look through repo to see where I can add setting record settings
- [ ] Attend Jonathan's presentation and due peer review
#### Thursday August 4th ####
- [ ] Attended Jonathan's presentation
- [ ] Completed peer review
- [ ] Looked through Hanwha camera client
- [ ] Atempted unsussesfully to get client to run
- [ ] Looked through Hanwha documentation and took record of settings we have to change with commands
```
Resolution, Framerate, Record, overwrite
relevant commands found in: Applications: 4.2, 5.2, 5.1 and vid &audio:2.4.4.2
```
- [ ] Found that there was an option to download and upload config settings
- [ ] Talked to Raj he pointed to curl command that I should use
- [ ] Worked on research paper

Things to do: 
- [ ] Finish research paper
- [ ] Finish process to upload config files
#### Friday August 5th ####
- [ ] Finished and submitted research paper
- [ ] Downloaded config.bin using url in browser
- [ ] Command to upload config failed
- [ ] Asked Raj he showed me that the source of my ploblem was: I didn't convert file format, had command on two lines, needed to rearrage command to put "Expect" before sent data
- [ ] Finished commands [here](https://github.com/waggle-sensor/summer2022/blob/main/pritchard/WiseNetCamera/download%26upload_Config.md)





